{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulokuriki/siim_2022_turnkey_segment/blob/main/ML_Ed_AutoSeg_001_with_Submitter_05_june_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUDE4m72QMGY"
      },
      "source": [
        "![picture](https://raw.githubusercontent.com/paulokuriki/siim_2022_turnkey_segment/main/siim22_banner_generic_800.png)\n",
        "\n",
        "# Segmenting kidneys in MRI images\n",
        "\n",
        "## SIIM Github Repo\n",
        "\n",
        "### Task\n",
        "\n",
        "In this tutorial we will explore implementing an automated segmentation method. The challenge is to create a method for performing segmentation of kidneys in MRI images of mice.  The data set consists of 150 axial MRI images from a variety of mouse models.  The kidneys were manually segmented and you will use these manual segmentations to develop your own deep learning model. You can read more about this data set in [Edwards et al. (2021)](https://pubmed.ncbi.nlm.nih.gov/32828755/).\n",
        "\n",
        "### Requirements\n",
        "\n",
        "  1. Basic understanding of machine learning and deep learning\n",
        "\n",
        "  2. Programming in Python\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "  1. To train a deep learning segmentation model and learn the basics of keras\n",
        "  \n",
        "  2. To learn to interpret the results of training and validation\n",
        "  \n",
        "  3. To identify beneficial avenues for improving peformance.\n",
        "\n",
        "### Acknowledgments\n",
        "\n",
        "This notebook was developed by the SIIM ML Education Sub-Committee and authored by Timothy L. Kline and Darryl E. Wright. The dataset is made available at: 'https://github.com/ImagingInformatics/machine-learning/tree/master/Education/KerasSegmentation'. Details related to this study are available in: https://kidneyinternational-online.org/action/showPdf?pii=S0085-2538%2820%2930957-1\n",
        "\n",
        "If you have questions, please contact: kline.timothy@mayo.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSgPmYp6QKJA"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Setting your Team Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T66h6euxP5Wa"
      },
      "outputs": [],
      "source": [
        "# Enter your Team Name below\n",
        "team = \"SIIM 2022\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Your Team Name is:\", team)"
      ],
      "metadata": {
        "id": "VvYHbNDmWc_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VqnmRcFQMGZ"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Required libraries\n",
        "\n",
        "Note: you can pip install directly in your jupyter notebook. Just add an exclamation point at the beginning (this allows you to execute Terminal commands within a jupyter notebook).\n",
        "\n",
        "Example: `!pip install keras-unet`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtJvSwUwNo6m"
      },
      "outputs": [],
      "source": [
        "# Install missing components for colab\n",
        "!pip install keras_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eaBSAsKM_Ih"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import measure\n",
        "from skimage.transform import resize\n",
        "from keras_unet.metrics import dice_coef\n",
        "from keras_unet.models import custom_unet\n",
        "from keras_unet.losses import jaccard_distance\n",
        "from sklearn.model_selection import train_test_split\n",
        "import requests\n",
        "\n",
        "def sub_model(team, hyperparam):\n",
        "  url='https://bids-class.azurewebsites.net/submit-model'\n",
        "  hyperparam['team']=team\n",
        "  hyperparam['ModelKey']='SIIM_AutoSeg_001'\n",
        "  x=requests.post(url,data=hyperparam)\n",
        "  if x.status_code==200:\n",
        "      print(f\"Model Submitted Successfully for team {team}\")\n",
        "  else:\n",
        "      print(\"Failed to Submit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC1noYM-QMGc"
      },
      "source": [
        "### Clone the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WS59KhBnQMGc"
      },
      "outputs": [],
      "source": [
        "!git clone 'https://github.com/TLKline/AutoTKV_MouseMRI/' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RurpnATBQMGd"
      },
      "source": [
        "\n",
        "---\n",
        "# Data preparation and familiarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejkl9MGbQMGd"
      },
      "source": [
        "## Read in the data set\n",
        "\n",
        "We are now in a position to read in the data.  We will start by reading in the names of the files and corresponding segmentations.  We will also create an array called ```indices``` that we will use to index into the ```images``` and ```segmentations``` arrays in the next step. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCWt8GP_QMGe"
      },
      "outputs": [],
      "source": [
        "data_path = 'AutoTKV_MouseMRI/AllTrainingImages/'\n",
        "images = []\n",
        "segmentations = []\n",
        "for f in os.listdir(data_path):\n",
        "  if 'label' in f:\n",
        "    continue\n",
        "  else:\n",
        "    images.append(f)\n",
        "    segmentations.append(f.replace('.nii', '-label.nii'))\n",
        "    \n",
        "print(\"Sample dataset files:\")\n",
        "print(\"Study:\",images[0])\n",
        "print(\"Segmentation Mask:\", segmentations[0])\n",
        "images = np.array(images)\n",
        "segmentations = np.array(segmentations)\n",
        "\n",
        "indices = np.array(range(len(images))) # we will use this in the next step."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices"
      ],
      "metadata": {
        "id": "KprMskBnXpkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRJqQjC9QMGe"
      },
      "source": [
        "---\n",
        "## Train-validation-test split\n",
        "\n",
        "### Use ```sklearn.model_selection.train_test_split``` to split the data into training and test partitions.\n",
        "\n",
        "The next step is to define the training, validation and test sets.  Use ```sklearn.model_selection.train_test_split``` and the ```indices``` array to create two new arrays with indices corresponding to a training partition with 75% of the data set and a test partition with 25% of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG6qaA56QMGf"
      },
      "outputs": [],
      "source": [
        "# split indices into training and test partitions\n",
        "train, test = train_test_split(indices, test_size=0.25, random_state=42) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSCQX2DXQMGf"
      },
      "source": [
        "### Use ```sklearn.model_selection.train_test_split``` to split a validation set from the training partition.\n",
        "Define a training and validation split. Use ```sklearn.model_selection.train_test_split``` and the ```train``` array to create two new arrays with indices corresponding to a training partition with 75% of the data set and a validation parition with 25% of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OeMwRhWQMGf"
      },
      "outputs": [],
      "source": [
        "# split train into training and validation partitions\n",
        "train, valid = train_test_split(train, test_size=0.25, random_state=42) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEMBq5hxQMGg"
      },
      "source": [
        "Let's see how these ```train```, ```valid``` and ```test``` arrays look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQtb9KRPQMGg"
      },
      "outputs": [],
      "source": [
        "print(train)\n",
        "print(valid)\n",
        "print(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GZmrqkFQMGg"
      },
      "source": [
        "Let's double check that there is no overlap in the partitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntcgjPhNQMGg"
      },
      "outputs": [],
      "source": [
        "assert list(np.intersect1d(train, valid)) == []\n",
        "assert list(np.intersect1d(train, test)) == []\n",
        "assert list(np.intersect1d(valid, test)) == []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ESe10dkQMGh"
      },
      "source": [
        "Below is a helper function that demonstrates how to read a .nii.gz file with [nibabel](https://nipy.org/nibabel/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YduqQigpQMGh"
      },
      "outputs": [],
      "source": [
        "def read_nifti_file(path):\n",
        "  nib_object = nib.load(path)\n",
        "  nib_data = nib_object.get_fdata()\n",
        "  nib_data = np.rot90(nib_data,3)\n",
        "  return nib_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XUHkM4FQMGi"
      },
      "source": [
        "We will use this function to help familiarise ourselves with the format of the data.\n",
        "\n",
        "## Read in an example image and the corresponding segmentation.\n",
        "\n",
        "Use the above function to read in the first image and segmentation from the training partition and inspect that shape of the returned matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCscgu3yQMGi"
      },
      "outputs": [],
      "source": [
        "# Read in the first study image and segmentation from the training partition\n",
        "example_image = read_nifti_file(data_path+images[train][0]) \n",
        "example_segmentation = read_nifti_file(data_path+segmentations[train][0])  \n",
        "\n",
        "print(example_image.shape, example_segmentation.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjVrPHKpQMGj"
      },
      "source": [
        "## Visualise the first slice from both the image and segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT8jA4W0QMGj"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,10))\n",
        "ax1 = fig.add_subplot(121)\n",
        "# Display the first slice from the image\n",
        "ax1.imshow(example_image[:,:,0], cmap='gray') \n",
        "ax1.axis('off')\n",
        "ax2 = fig.add_subplot(122)\n",
        "# Display the first slice from the segmentation\n",
        "ax2.imshow(example_segmentation[:,:,0])  \n",
        "ax2.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJNn23gkQMGj"
      },
      "source": [
        "## Visualise the tenth slice from both the image and segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDza21RLQMGj"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,10))\n",
        "ax1 = fig.add_subplot(121)\n",
        "# Display the tenth slice from the image\n",
        "ax1.imshow(example_image[:,:,10], cmap='gray') \n",
        "ax1.axis('off')\n",
        "ax2 = fig.add_subplot(122)\n",
        "# Display the tenth slice from the segmentation\n",
        "ax2.imshow(example_segmentation[:,:,10])  \n",
        "ax2.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uch7I-RpQMGj"
      },
      "source": [
        "---\n",
        "# Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRDJ47NNQMGj"
      },
      "source": [
        "Below is a second helper function that relies on ```read_nifti_file``` to read the images and segmentation files to create the data matrices we require when working with neural networks.  This function also implements resizing of the image slices to a default of 64-by-64 pixels.\n",
        "\n",
        "## Why do we resize the images?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXjHbO5ZQMGk"
      },
      "source": [
        "  1. To ensure all image slices are the same size to feed to the U-Net.\n",
        "  \n",
        "  2. To reduce the dimensionality of the data for faster training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGDLQDPXQMGk"
      },
      "outputs": [],
      "source": [
        "def retrieve_images_and_segmentations(data_path, images, segmentations, size=(128,128)):\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(len(images)):\n",
        "    seg = read_nifti_file(data_path+segmentations[i])\n",
        "    img = read_nifti_file(data_path+images[i])\n",
        "    assert img.shape == seg.shape\n",
        "    seg = resize(seg,(size[0], size[1], seg.shape[-1]))\n",
        "    img = resize(img,(size[0], size[1], img.shape[-1]))\n",
        "    for j in range(seg.shape[-1]):\n",
        "      # ignore slices that don't have a segmentation\n",
        "      if np.sum(seg[:,:,j]) == 0:\n",
        "        continue\n",
        "      x.append(img[:,:,j])\n",
        "      y.append(seg[:,:,j])\n",
        "  x = np.array(x)[:,:,:,np.newaxis]\n",
        "  y = np.clip(np.array(y)[:,:,:,np.newaxis], 0, 1)\n",
        "\n",
        "  # randomly shuffle slices\n",
        "  m = x.shape[0]\n",
        "  order = np.random.permutation(m)\n",
        "\n",
        "  return x[order], y[order]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HndvgcSLQMGk"
      },
      "source": [
        "The function above also ignores image slices with no corresponding segmentation and treats each slice as an independent training example.  This \"bakes in\" two assumptions:\n",
        "\n",
        "  1. that slices with no segmentation provide no useful information for training\n",
        "  \n",
        "  2. that the information in one slice has no dependence on the preceeding or subsequent images in the image volume.\n",
        "  \n",
        "Think about the implications of these assumptions and why we chose them here.  Which of these assumptions might have the greatest impact on the performance we might be able to achieve?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNHIwOWzQMGk"
      },
      "source": [
        "## Get the data matrices for each of the partitions.\n",
        "\n",
        "Use ```retrieve_images_and_segmentations``` to retrieve the image and segmentation matrices we need to develop and test our model.  Use the ``train```, ```valid``` and ```test``` arrays we defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YbzGuMLQMGk"
      },
      "outputs": [],
      "source": [
        "# Get the matrices for the training partition\n",
        "x_train, y_train = retrieve_images_and_segmentations(data_path, images[train], segmentations[train]) \n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maXSnci0QMGl"
      },
      "outputs": [],
      "source": [
        "# Get the matrices for the validation partition\n",
        "x_valid, y_valid = retrieve_images_and_segmentations(data_path, images[valid], segmentations[valid]) \n",
        "print(x_valid.shape, y_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQvcl6gQQMGl"
      },
      "outputs": [],
      "source": [
        "# Get the matrices for the test partition\n",
        "x_test, y_test = retrieve_images_and_segmentations(data_path, images[test], segmentations[test]) \n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_7WshoMQMGl"
      },
      "source": [
        "## Visualize the training data\n",
        "\n",
        "Let's perform a sanity check to ensure that the data matrices we have just created look correct before we try training a model.\n",
        "\n",
        "It is common to visualise the segmentations as contours overlaid on the image.  To do this we use ```skimage.measure.find_contours``` to find contours in the segmentation masks.  We will also modify this function later to visualize the results of the model we train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRJRUjagQMGl"
      },
      "outputs": [],
      "source": [
        "def visualise_data(x, y):\n",
        "  n=4\n",
        "  dim = int(np.ceil(np.sqrt(n)))\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  for i in range(n):\n",
        "    ax = fig.add_subplot(dim, dim, i+1)\n",
        "    ax.imshow(x[50*i,:,:,0], cmap='gray')\n",
        "    contours = measure.find_contours(y[50*i,:,:,0], .99)\n",
        "    for idx, contour in enumerate(contours):\n",
        "      ax.plot(contour[:,1], contour[:,0], color='#FB3640', lw=4, label=f'kidney {idx+1}')\n",
        "      ax.legend()\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neFGOeqZQMGm"
      },
      "source": [
        "Here we visualise the first 4 images from the training partition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O-QNgOeQMGm"
      },
      "outputs": [],
      "source": [
        "visualise_data(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ukbaEBPQMGm"
      },
      "source": [
        "---\n",
        "# Training the model\n",
        "\n",
        "We are now ready to train a model to segment the kidneys.\n",
        "\n",
        "To do this we will use a [U-Net](https://arxiv.org/pdf/1505.04597.pdf) architecture.  We are also going to use the [Keras](https://keras.io/) Python deep learning API to build and train a model.  There are great starter guides to Keras [here](https://keras.io/getting_started/), lots of code examples [here](https://keras.io/examples/) and even an example of how to build a U-Net-like architecture from scratch in Keras [here](https://keras.io/examples/vision/oxford_pets_image_segmentation/).\n",
        "\n",
        "In this notebook, we are going to focus on the very high level API and take advantage of the [karolzak/keras-unet github repository](https://github.com/karolzak/keras-unet) that implements a number of U-Net type architectures which you install in the first TODO for this notebook.\n",
        "\n",
        "The high level API requires three steps:\n",
        "\n",
        "  1. instantiate a [Model](https://keras.io/api/models/model/#model-class) object.\n",
        "  \n",
        "  2. compile the model\n",
        "  \n",
        "  3. fit the model to the data\n",
        "  \n",
        "In general, the Model object exposes methods similar to the sklearn API such as ```.fit``` and ```.predict``` along with other neural network specific methods.\n",
        "\n",
        "\n",
        "### 1. Instantiate a custom_unet object using the correct input_shape\n",
        "\n",
        "To start we will instantiate a [custom_unet](https://github.com/karolzak/keras-unet/blob/master/keras_unet/models/custom_unet.py) object from the [karolzak/keras-unet repository](https://github.com/karolzak/keras-unet).  Use the correct ```input_shape``` given our data set and leave all other parameters as defaults.\n",
        "\n",
        "### 2. Compile the model\n",
        "\n",
        "Use the ```jaccard_distance``` as the loss function, ```dice_coef``` as a metric to track and use the ```tf.keras.optimizers.Adam``` optimizer with a learning rate of 3e-4.\n",
        "\n",
        "### 3. Fit the model \n",
        "\n",
        "Finally, use your ```training set``` to fit your model and use the ```validation_data``` parameters of the fit method to track the performance on the validation set. Train the  model for 10 epochs.  Assign the result of fit to the ```history``` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97Vs3HeWQMGm"
      },
      "outputs": [],
      "source": [
        "# Instantiate the custom_unet object\n",
        "model = custom_unet(input_shape=(128, 128, 1)) \n",
        "\n",
        "# Compile the model as described above\n",
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4), \n",
        "  loss=jaccard_distance,\n",
        "  metrics=[dice_coef])\n",
        "\n",
        "# Fit the model to the training data, track performance on the validation set and train it for 5 epochs.\n",
        "history = model.fit(x_train, y_train, \n",
        "                    validation_data=(x_valid, y_valid), \n",
        "                    epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OndjuKKBQMGn"
      },
      "source": [
        "---\n",
        "# Evaluating model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9vqBcjfQMGn"
      },
      "source": [
        "Here we inspect the returned training history.  \n",
        "The ```history.history``` object tracks the loss and metrics for each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtcputzLQMGn"
      },
      "outputs": [],
      "source": [
        "print(history.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-GCbxM0QMGn"
      },
      "source": [
        "## Learning curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EVaw8k5QMGn"
      },
      "source": [
        "### Plot both the training and validation loss learning curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrEd2k9HQMGn"
      },
      "outputs": [],
      "source": [
        "# Plot the training and validation losses learning curves\n",
        "plt.plot(range(len(history.history['loss'])), history.history['loss'], '-', label='loss') \n",
        "plt.plot(range(len(history.history['val_loss'])), history.history['val_loss'], '-', label='val_loss')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.xlabel('epoch')\n",
        "plt.title('Jaccard loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot both the training and validation Dice coefficients"
      ],
      "metadata": {
        "id": "2IUfGJy-P5RM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRlhRZ8hQMGn"
      },
      "outputs": [],
      "source": [
        "# Plot the training and validation dice_coef learning curves\n",
        "plt.plot(range(len(history.history['dice_coef'])), history.history['dice_coef'], '-', label='dice_coef') \n",
        "plt.plot(range(len(history.history['val_dice_coef'])), history.history['val_dice_coef'], '-', label='val_dice_coef') \n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel('epoch')\n",
        "plt.title('Dice coefficient')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZUDAYrnQMGo"
      },
      "source": [
        "### In the cell below briefly describe what you can conclude from these learning curves.  What is the simplest change we could make to the training proceedure to help improve performance?\n",
        "\n",
        "### Based on the training curves, what changes can you make to the training procedure?\n",
        "\n",
        "For one, train the model for more epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVzEgEobQMGo"
      },
      "source": [
        "---\n",
        "## Evaluating segmentation performance\n",
        "\n",
        "### Use the trained model to predict on the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFq-J1Y3QMGo"
      },
      "outputs": [],
      "source": [
        "# Predict on the training set\n",
        "y_pred_train = model.predict(x_train) \n",
        "y_pred_train = y_pred_train.astype('float') # casting to type float to avoid ValueError later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUKwh2xcQMGo"
      },
      "source": [
        "### Calculate the Dice coefficient between the manual and predicted segmentations for the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZ6SZADCQMGo"
      },
      "outputs": [],
      "source": [
        "print(\"Dice in train set:\", np.array(dice_coef(y_train, y_pred_train.astype('float'))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSU2ieZbQMGo"
      },
      "source": [
        "### Similarly calculate the Dice coefficient on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5m9EinWQMGp"
      },
      "outputs": [],
      "source": [
        "# Predict on the validation set\n",
        "y_pred_valid = model.predict(x_valid) \n",
        "y_pred_valid = y_pred_valid.astype('float') # casting to type float to avoid ValueError later\n",
        "print(\"Dice in validation set:\", np.array(dice_coef(y_valid, y_pred_valid.astype('float'))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjJlcTW_QMGp"
      },
      "source": [
        "What do you make of this comparison of Dice coefficients measured on the training and validation sets? Is this performance good enough? Let's gather more evidence by visualising some of the segmentations.\n",
        "\n",
        "Below is a modification of the ```visualise_data()``` method we used above. This modified version allows to visualise both the groundtruth (manual) and predicted segmentations.  The groundtruth segmentation is shown in red and the predicted segmentaiton is shown in blue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTZRwR20QMGp"
      },
      "outputs": [],
      "source": [
        "def visualise_data_and_prediction(x, y, y_pred, dataset = ''):\n",
        "  n=4\n",
        "  dim = int(np.ceil(np.sqrt(n)))\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  for i in range(n):\n",
        "    ax = fig.add_subplot(dim, dim, i+1)\n",
        "    ax.imshow(x[50*i,:,:,0], cmap='gray')\n",
        "    contours = measure.find_contours(y[50*i,:,:,0], .99)\n",
        "    for idx, contour in enumerate(contours):\n",
        "      if idx == 0:\n",
        "        ax.plot(contour[:,1], contour[:,0], color='#FB3640', lw=4, label=dataset+' groundtruth')\n",
        "        ax.legend()\n",
        "      else:\n",
        "        ax.plot(contour[:,1], contour[:,0], color='#FB3640', lw=4)\n",
        "    contours = measure.find_contours(y_pred[50*i,:,:,0], .99)\n",
        "    for idx, contour in enumerate(contours):\n",
        "      if idx == 0:\n",
        "        ax.plot(contour[:,1], contour[:,0], color='#35A7FF', lw=4, label=dataset+' predicted')\n",
        "        ax.legend()\n",
        "      else:\n",
        "        ax.plot(contour[:,1], contour[:,0], color='#35A7FF', lw=4)        \n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgO6cEl0QMGp"
      },
      "outputs": [],
      "source": [
        "visualise_data_and_prediction(x_train, y_train, y_pred_train, 'train set')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMFLMi3UQMGp"
      },
      "outputs": [],
      "source": [
        "visualise_data_and_prediction(x_valid, y_valid, y_pred_valid, 'validation set')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGyhbEQqQMGp"
      },
      "source": [
        "### Given the evidence we have gathered do you think we are in the high bias or high variance regime? Provide your answer and justification in the cell below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dutAZrb0QMGp"
      },
      "source": [
        "# What are you seeing: High bias or high variance? Justify your answer.\n",
        "\n",
        "**High bias**. Both the training and validation dice coefficients are low and similar.  Visually, the model is performing poorly on both the training and validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKy2kVibQMGq"
      },
      "source": [
        "# Improving performance.\n",
        "\n",
        "### Now it's your time!\n",
        "\n",
        "Implement changes to the training procedure based on that you analysed earlier then replicate it below.  Ensure the changes you make runs in a reasonable time (< 10 mins). \n",
        "\n",
        "As guidance, in Google Colab, training process takes ~20 seconds per epoch.  This may be significantly different for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3GVVMMmQMGq"
      },
      "outputs": [],
      "source": [
        "############################################################################################\n",
        "\n",
        "# Change the parameters below and run this cell again\n",
        "\n",
        "hyperparam = {\n",
        "    'LearningRate': 3e-4,\n",
        "    'BatchSize': 32,\n",
        "    'Epochs': 10,\n",
        "    'ImageSize': 64,\n",
        "    'BatchNorm': True,\n",
        "    'Filters': 16,\n",
        "    'Dropout': 0.1\n",
        "}\n",
        "\n",
        "\n",
        "############################################################################################\n",
        "\n",
        "\n",
        "model = custom_unet(input_shape=(hyperparam['ImageSize'], hyperparam['ImageSize'], 1), \n",
        "                    dropout=hyperparam['Dropout'], \n",
        "                    use_batch_norm=hyperparam['BatchNorm'],\n",
        "                    filters=hyperparam['Filters']\n",
        "                    ) \n",
        "\n",
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=hyperparam['LearningRate']), \n",
        "  loss=jaccard_distance,\n",
        "  metrics=[dice_coef])\n",
        "\n",
        "if x_train.shape[1] != hyperparam['ImageSize']:\n",
        "  x_train, y_train = retrieve_images_and_segmentations(data_path, images[train], segmentations[train], size=(hyperparam['ImageSize'], hyperparam['ImageSize'])) \n",
        "  x_valid, y_valid = retrieve_images_and_segmentations(data_path, images[valid], segmentations[valid], size=(hyperparam['ImageSize'], hyperparam['ImageSize'])) \n",
        "  x_test, y_test = retrieve_images_and_segmentations(data_path, images[test], segmentations[test], size=(hyperparam['ImageSize'], hyperparam['ImageSize'])) \n",
        "\n",
        "history = model.fit(x_train, y_train, \n",
        "                    validation_data=(x_valid, y_valid), \n",
        "                    epochs=hyperparam['Epochs'], batch_size=hyperparam['BatchSize'])\n",
        "\n",
        "plt.plot(range(len(history.history['loss'])), history.history['loss'], '-', label='loss') \n",
        "plt.plot(range(len(history.history['val_loss'])), history.history['val_loss'], '-', label='val_loss') \n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.xlabel('epoch')\n",
        "plt.title('Jaccard loss')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(history.history['dice_coef'])), history.history['dice_coef'], '-', label='dice_coef')\n",
        "plt.plot(range(len(history.history['val_dice_coef'])), history.history['val_dice_coef'], '-', label='val_dice_coef') \n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel('epoch')\n",
        "plt.title('Dice coefficient')\n",
        "plt.show()\n",
        "\n",
        "y_pred_train = model.predict(x_train) \n",
        "y_pred_train = y_pred_train.astype('float') \n",
        "print(\"Dice in train set:\", np.array(dice_coef(y_train, y_pred_train.astype('float'))))\n",
        "visualise_data_and_prediction(x_train, y_train, y_pred_train, 'train set')\n",
        "\n",
        "y_pred_valid = model.predict(x_valid) \n",
        "y_pred_valid = y_pred_valid.astype('float') \n",
        "print(\"Dice in validation set:\", float(dice_coef(y_valid, y_pred_valid.astype('float'))))\n",
        "visualise_data_and_prediction(x_valid, y_valid, y_pred_valid, 'validation set')\n",
        "\n",
        "y_pred_test = model.predict(x_test) \n",
        "y_pred_test = y_pred_test.astype('float') \n",
        "hyperparam['metric'] = float(dice_coef(y_test, y_pred_test.astype('float')))\n",
        "print(\"Dice in test set:\", hyperparam['metric'])\n",
        "visualise_data_and_prediction(x_test, y_test, y_pred_test, 'test set')\n",
        "\n",
        "sub_model(team, hyperparam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i3KAJwhQMGt"
      },
      "source": [
        "# Analysing your results\n",
        "\n",
        "### Did your performance improve? What is the greatest source of error now, bias or variance?\n",
        "\n",
        "### Analyse your dice coefficient and compare your results.\n",
        "\n",
        "### Then, go back to the section \"Improving Performance\" above to tune different hyperparameters and try to improve your metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZEj8FbmQMGu"
      },
      "source": [
        "## Below are suggestions for how this experiment could be modified.\n",
        "\n",
        "  1. explore the keras_unet [github repository](https://github.com/karolzak/keras-unet). What parameters of the model could we change to further improve performance? How would you setup an experiment to find the best settings for these parameters?\n",
        "\n",
        "  2. replicate the analysis of [Edwards et al. (2021)](https://reader.elsevier.com/reader/sd/pii/S0085253820309571?token=8C46B51948D5C9822571903C855A46B2A114B98D334C1F1FD510E5FB512D933E2D9D6C4DB40EF0B60E29118E61F6F0A6&originRegion=us-east-1&originCreation=20210823192742) comparing the automatic segmentations to the manual segmentations as closely as you can given the information you have access to.  Is there any bias in how the model segments in comparison to manual segmentations?\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ML_Ed_AutoSeg_001_with_Submitter_05_june_v1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}